{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37319a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import time\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0775a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Bucuresti\n",
      "End: Babadag\n"
     ]
    }
   ],
   "source": [
    "# Nodurile din graf\n",
    "cities = ['Bucuresti',\n",
    "          'Craiova',\n",
    "          'Brasov',\n",
    "          'Pitesti',\n",
    "          'Babadag',\n",
    "          'Sibiu',\n",
    "          'Cluj'\n",
    "          ]\n",
    "\n",
    "\n",
    "# Matricea de costuri\n",
    "cost_matrix = np.array([\n",
    "    [0, 3, 5, 10, 0, 0, 100],\n",
    "    [0, 0, 0, 4, 0, 0, 0],\n",
    "    [0, 0, 0, 4, 9, 3, 0],\n",
    "    [0, 3, 0, 0, 2, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 4, 0, 5],\n",
    "    [0, 0, 3, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "start_city = 0  # Bucuresti\n",
    "end_city = 4   # Craiova\n",
    "\n",
    "\n",
    "print(f\"Start: {cities[start_city]}\")\n",
    "print(f\"End: {cities[end_city]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664930c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, cost_matrix, start, end, city_names=None, learning_rate=0.5, discount_factor=0.95, exploration_rate=0.5):\n",
    "\n",
    "        self.cost_matrix = cost_matrix\n",
    "        self.n_states = len(cost_matrix)\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.city_names = city_names\n",
    "        \n",
    "        self.learning_rate = learning_rate    \n",
    "        self.discount_factor = discount_factor   \n",
    "        self.exploration_rate = exploration_rate \n",
    "\n",
    "        # Initializeaza Qtable cu zerouri\n",
    "        self.q_table = np.zeros((self.n_states, self.n_states))\n",
    "        \n",
    "    def get_neighbors(self, state):\n",
    "        # Returneaza lista de noduri vecine\n",
    "        return [i for i in range(self.n_states) if self.cost_matrix[state][i] > 0]\n",
    "    \n",
    "    # Calculeaza recompensa pentru o actiune data\n",
    "    def get_reward(self, state, action):\n",
    "        # Costul din matricea de costuri\n",
    "        cost = self.cost_matrix[state][action]\n",
    "        #Daca actiunea duce la nodul final recompensa este mare\n",
    "        if action == self.end:\n",
    "            return 10000 / cost\n",
    "        # Recompensa este negativa proportional cu costul\n",
    "        else:\n",
    "            return -100 * cost\n",
    "    \n",
    "\n",
    "    def choose_action(self, state, neighbors):\n",
    "\n",
    "        # In functie de exploration rate ul dat ca parametru al fuctiei alege daca sa\n",
    "        #mearga agentul pe un drum aleatoriu sau pe cel cu cea mai mare valoare Q\n",
    "\n",
    "        #in cazul de exploration_rate=0.5 sansa de a alege un drum aleator este de 50%\n",
    "        if np.random.random() < self.exploration_rate:\n",
    "            #nod vecin random\n",
    "            return np.random.choice(neighbors)\n",
    "        else:\n",
    "            #Lista cu valorile Q pentru nodurile vecine\n",
    "            q_vals = [self.q_table[state][n] for n in neighbors]\n",
    "            max_q = max(q_vals)\n",
    "            #Lista cu nodurile vecine care au valoarea Q maxima\n",
    "            best_actions = [n for i, n in enumerate(neighbors) if q_vals[i] == max_q]\n",
    "            return np.random.choice(best_actions)\n",
    "    \n",
    "    def train(self, episodes=10000, max_steps=15):\n",
    "\n",
    "        for ep in range(episodes):\n",
    "            state = self.start\n",
    "            steps = 0\n",
    "\n",
    "            #Ruleaza pana cand ajunge la nodul final sau depaseste numarul maxim de pasi\n",
    "            while state != self.end and steps < max_steps:\n",
    "                neighbors = self.get_neighbors(state)\n",
    "                #Daca nu are vecini iese din loop\n",
    "                if not neighbors:\n",
    "                    break\n",
    "\n",
    "                action = self.choose_action(state, neighbors)\n",
    "                reward = self.get_reward(state, action)\n",
    "\n",
    "                #Vecinii urmatorului nod\n",
    "                next_neighbors = self.get_neighbors(action)\n",
    "                #Valoarea Q maxima dintre vecinii urmatorului nod\n",
    "                max_next_q = max([self.q_table[action][n] for n in next_neighbors]) if next_neighbors else 0\n",
    "                \n",
    "                #Formula lui Bellman pentru actualizarea valorii Q\n",
    "                self.q_table[state][action] += self.learning_rate * (reward + self.discount_factor * max_next_q - self.q_table[state][action])\n",
    "                \n",
    "                #Trece la urmatorul nod si se incrementeaza numarul de pasi\n",
    "                state = action\n",
    "                steps += 1\n",
    "            \n",
    "            #La fiecare 2000 de episoade scade exploration rate ul cu 10% pentru a favoriza exploatarea\n",
    "            if ep % 2000 == 0 and ep > 0:\n",
    "                self.exploration_rate = max(0.05, self.exploration_rate * 0.9)\n",
    "                print(f\"Episod {ep}/{episodes} | Exploration rate: {self.exploration_rate:.3f}\")\n",
    "    \n",
    "    def get_optimal_path(self):\n",
    "        path = [self.start]\n",
    "        state = self.start\n",
    "        #Folosim un set pentru a verifica daca un nod a fost deja vizitat\n",
    "        visited = set([self.start])\n",
    "        \n",
    "        while state != self.end and len(path) < 15:\n",
    "            neighbors = self.get_neighbors(state)\n",
    "            unvisited = [n for n in neighbors if n not in visited]\n",
    "\n",
    "            #Verificam doar nodurile care nu au fost vizitate\n",
    "            if not unvisited:\n",
    "                break\n",
    "            #Cea mai buna valoarea Q a dintre nodurile nevizitate\n",
    "            q_vals = [self.q_table[state][n] for n in unvisited]\n",
    "            best = unvisited[np.argmax(q_vals)]\n",
    "\n",
    "            #Adaugam nodul la path si il marcam ca vizitat\n",
    "            path.append(best)\n",
    "            visited.add(best)\n",
    "            state = best\n",
    "\n",
    "        return path\n",
    "    \n",
    "    def print_qtable(self):\n",
    "        print(\"\\nQTable:\")\n",
    "        for i in range(self.n_states):\n",
    "            neighbors = self.get_neighbors(i)\n",
    "            if neighbors:\n",
    "                print(self.city_names[i], \"->\", end=\" \")\n",
    "                for n in neighbors:\n",
    "                    print(f\"{self.city_names[n]}:{round(self.q_table[i][n],2)}\", end=\"  \")\n",
    "                print()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3435a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episod 2000/10000 | Exploration rate: 0.450\n",
      "Episod 4000/10000 | Exploration rate: 0.405\n",
      "Episod 6000/10000 | Exploration rate: 0.365\n",
      "Episod 8000/10000 | Exploration rate: 0.328\n",
      "\n",
      " Training completed in 1.3352813720703125 seconds\n"
     ]
    }
   ],
   "source": [
    "## Antrenarea agentului Q-Learning\n",
    "\n",
    "#Start la masurarea memoriei si a timpului\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "agent = QLearningAgent(cost_matrix, start_city, end_city, city_names=cities,\n",
    "                      learning_rate=0.5, discount_factor=0.95, exploration_rate=0.5)\n",
    "\n",
    "#Antreneaza agentul pentru 10000 de episoade\n",
    "agent.train(episodes=10000)\n",
    "\n",
    "#Stop la masurarea memoriei si a timpului\n",
    "end_time = time.time()\n",
    "current_mem, peak_mem = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(\"\\n Training completed in\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43837fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drum valid gasit\n",
      "Bucuresti -> Craiova -> Pitesti -> Babadag\n",
      "Cost total: 9.0\n",
      "Timp: 1.3353 sec\n",
      "Memorie: 14.67 KB\n",
      "\n",
      "QTable:\n",
      "Bucuresti -> Craiova:3832.5  Brasov:3632.5  Pitesti:3750.0  Cluj:-6359.12  \n",
      "Craiova -> Pitesti:4350.0  \n",
      "Brasov -> Pitesti:4350.0  Babadag:1111.11  Sibiu:2683.83  \n",
      "Pitesti -> Craiova:3832.5  Babadag:5000.0  \n",
      "Sibiu -> Babadag:2500.0  Cluj:3140.88  \n",
      "Cluj -> Brasov:3832.5  \n"
     ]
    }
   ],
   "source": [
    "# Drum optim si cost\n",
    "path = agent.get_optimal_path()\n",
    "path_names = [cities[i] for i in path]\n",
    "total_cost = sum(cost_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n",
    "\n",
    "if path[-1] == end_city:\n",
    "    print(\"Drum valid gasit\")\n",
    "else:\n",
    "    print(\"Drum incomplet\")\n",
    "\n",
    "print(\" -> \".join(path_names))\n",
    "print(f\"Cost total: {total_cost:.1f}\")\n",
    "\n",
    "# Performanta\n",
    "print(f\"Timp: {end_time - start_time:.4f} sec\")\n",
    "print(f\"Memorie: {peak_mem / 1024:.2f} KB\")\n",
    "\n",
    "# Afiseaza Qtable\n",
    "agent.print_qtable()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
